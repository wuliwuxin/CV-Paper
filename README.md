ç®€ä½“ä¸­æ–‡ | [English](README_EN.md)
# CV-Paper

æœ¬é¡¹ç›®ä¸»è¦æ˜¯æ–¹ä¾¿æ–°æ‰‹å­¦ä¹ å’Œè‡ªæˆ‘å›é¡¾ã€‚ç»å…¸ä¹‹æ‰€ä»¥æ˜¯ç»å…¸ï¼Œåœ¨äºå®ƒç‹¬ç‰¹çš„æ€æƒ³å’Œè´¨é‡çš„å¤§å¹…æå‡ã€‚æ­¤é¡¹ç›®ä¸»è¦æ˜¯å…³äºCVæ–¹å‘çš„è®ºæ–‡ï¼Œä¹Ÿå¯èƒ½ä¼šæœ‰NLPæ–¹å‘çš„éƒ¨åˆ†æ–‡ç« ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä¸ªäººçš„ä¸€äº›ç»éªŒï¼Œä»…ä¾›å‚è€ƒã€‚

æŒç»­æ›´æ–°ä¸­......

## å‰è¨€
### å¿…å­¦å†…å®¹--ä¹¦ç±ç¯‡
1. â€œè¥¿ç“œä¹¦â€å‘¨å¿—åè€å¸ˆçš„[ã€Šæœºå™¨å­¦ä¹ ã€‹](./book)ã€‚å…¬å¼æ¨å¯¼é…å¥—ä½¿ç”¨[â€œå—ç“œä¹¦â€](https://datawhalechina.github.io/pumpkin-book/#/)

2. [ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹](./book)--æèˆªè€å¸ˆã€‚

3. " èŠ±ä¹¦"[ã€Šæ·±åº¦å­¦ä¹ deep learningã€‹](./book)--2018å¹´å›¾çµå¥–æ½œå¿ƒæ‰“é€ çš„AIåœ£ç»ã€‚

4. [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh-v2.d2l.ai/)--äºšé©¬é€Šå›¢é˜Ÿçš„ææ²è€å¸ˆï¼ˆæ²ç¥ï¼‰æ·±åº¦å­¦ä¹ å¯å¹³æ˜“è¿‘äººï¼Œæ•™ä¼šä½ æ¦‚å¿µã€èƒŒæ™¯å’Œä»£ç ã€‚

### å¿…å­¦å†…å®¹--è§†é¢‘ç¯‡

1. pythonæ¨èå‘¨æ²«å‡¡çš„[è«çƒ¦python](https://mofanpy.com/)ã€‚PythonåŸºç¡€ éå¸¸é€‚åˆåˆšå…¥é—¨, æˆ–è€…æ˜¯ä»¥å‰ä½¿ç”¨è¿‡å…¶è¯­è¨€çš„æœ‹å‹ä»¬, æ¯ä¸€æ®µè§†é¢‘éƒ½ä¸ä¼šå¾ˆé•¿, èŠ‚èŠ‚ç›¸è¿, å¯¹äºè¿…é€ŸæŒæ¡åŸºç¡€çš„ä½¿ç”¨æ–¹æ³•å¾ˆæœ‰å¸®åŠ©ã€‚ä¸€ä¸ªé»˜é»˜å¥‰çŒ®åˆ†äº«è‡ªå·±æ‰€å­¦çš„ä¸œè¥¿çš„å¤§ä½¬ã€‚


2. æå®æ¯…çš„å…³äºæ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„è¯¾ç¨‹ã€‚æå®æ¯…çš„è§†é¢‘è®²å¾—éå¸¸éå¸¸å¥½ï¼Œè€Œä¸”è¯¦ç»†ï¼Œååˆ†æƒŠå¹ç«Ÿç„¶ä¼šæœ‰äºº è®²è¯¾è®²å¾—è¿™ä¹ˆå¥½ã€‚[æå®æ¯…æœºå™¨å­¦ä¹ ](https://www.bilibili.com/video/BV1Wv411h7kN?from=search&seid=12925803382584433478&spm_id_from=333.337.0.0)ï¼Œ[æå®æ¯…æ·±åº¦å­¦ä¹ ](https://www.bilibili.com/video/BV1JE411g7XF?from=search&seid=12925803382584433478&spm_id_from=333.337.0.0)


3. æµ™æ±Ÿå¤§å­¦èƒ¡æµ©åŸºè€å¸ˆ[ç ”ç©¶ç”Ÿæœºå™¨å­¦ä¹ è¯¾ç¨‹](https://www.bilibili.com/video/BV1dJ411B7gh)ã€‚äººæ‰‹å†™æ¿ä¹¦ï¼Œè€Œä¸”è®²çš„çœŸçš„å¤ªå¥½äº†ï¼Œæ•°å­¦æ¨å¯¼è¿‡ç¨‹è®²çš„ä¸€æ¸…äºŒæ¥šã€‚å¯ä»¥æ­é…æèˆªã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸€åŒé£Ÿç”¨ã€‚å¾ˆå¤šä¹¦ä¸­æ²¡è®²æ¸…æ¥šçš„æ¨å¯¼ï¼Œå¬äº†èƒ¡è€å¸ˆçš„è®²è§£åæç„¶å¤§æ‚Ÿã€‚ä¸€ä¸ªè®²è¯¾è®²åˆ°å…¨èº«æ¹¿é€çš„è€å¸ˆã€‚


4. æé£é£çš„ [csn231 è¯¾ç¨‹](https://www.bilibili.com/video/BV1nJ411z7fe?from=search&seid=6244444160908607298&spm_id_from=333.337.0.0)ã€‚è¿™ä¸ªè¯¾ç¨‹æˆ‘æ²¡æœ‰å®Œæ•´çœ‹è¿‡ã€‚ä½†è¿™æ˜¯å¾ˆå¤šäººéƒ½æ¨èå¿…çœ‹çš„ä¸€ä¸ªå…¥é—¨è§†é¢‘ã€‚


5. å´æ©è¾¾è€å¸ˆæ–¯å¦ç¦[æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://www.bilibili.com/video/BV1VK4y1d7fj)ã€‚è‹±è¯­åº•å­å¥½çš„å°ä¼™ä¼´å¯ä»¥çœ‹å´æ©è¾¾å¤§ä½¬çš„å…¨è‹±è§†é¢‘ã€‚




* [å›¾åƒåˆ†ç±»](#å›¾åƒåˆ†ç±»)
* [ç›®æ ‡æ£€æµ‹](#ç›®æ ‡æ£€æµ‹)
* [å›¾åƒåˆ†å‰²](#å›¾åƒåˆ†å‰²)
* [åŒ»å­¦å½±åƒç›¸å…³](#åŒ»å­¦å½±åƒç›¸å…³)
* [å°æ ·æœ¬å­¦ä¹ å’Œå…ƒå­¦ä¹ ](#å°æ ·æœ¬å­¦ä¹ å’Œå…ƒå­¦ä¹ )
* [CVä¸­çš„Attentionæœºåˆ¶](#CVä¸­çš„Attentionæœºåˆ¶)
* [å…¶ä»–](#å…¶ä»–)
* [å¸¸ç”¨æ•°æ®é›†](#å¸¸ç”¨æ•°æ®é›†)



## å›¾åƒåˆ†ç±»
- [LeNet](https://ieeexplore.ieee.org/document/726791)

![](/picture/LeNet-5.png)

 1998å¹´ã€ŠGradient-Based Learning Applied to Document Recognitionã€‹ CNNçš„å¼€å±±ä¹‹ä½œï¼Œä¹Ÿæ˜¯æ‰‹å†™ä½“è¯†åˆ«ç»å…¸è®ºæ–‡ã€‚åªè¦åŒ…å«äº†å·ç§¯å±‚çš„ç½‘ç»œéƒ½å¯ç†è§£ä¸ºå·ç§¯ç¥ç»ç½‘ç»œ

- [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

![](/picture/AlexNet.png)

 2012å¹´ã€ŠImageNet Classification with Deep Convolutional Neural Networks ã€‹ ILSVRC-2012 å¤§èµ›å† å†›ï¼Œä¿ƒè¿›CNNçš„æ‰›é¼ä¹‹ä½œï¼ŒAlexNetæ˜¯CNNå‘å±•å²ä¸Šçš„ä¸€ä¸ªå†å²æ€§è½¬æŠ˜ï¼Œä¸èƒ½ä¸è¯»ã€‚
 
 [è®ºæ–‡ç†è§£](/notes/AlexNet.md)

- [ZFNet](https://arxiv.org/abs/1311.2901)

AlexNetå¤æ‚æ¨¡å‹çš„å†…éƒ¨è¿ä½œå’Œè¡Œä¸ºï¼Œæˆ–å®ƒä»¬å¦‚ä½•å–å¾—å¦‚æ­¤å¥½çš„æ€§èƒ½ï¼Œä»ç„¶æ²¡æœ‰ä»€ä¹ˆæ·±å…¥äº†è§£ã€‚ä½ å¦‚æ­¤ä¼˜ç§€ï¼Œæˆ‘è¿˜ä¸çŸ¥é“ä½ ä¸ºä»€ä¹ˆè¿™ä¹ˆä¼˜ç§€ã€‚å—¯ï¼Œæˆ‘å¿…é¡»è¦äº†è§£ä½ ä¸€ä¸‹ã€‚ã€ŒğŸ¤”ã€

ZFNet æ­£æ˜¯å¯¹ AlexNet è¿›è¡Œå¯è§† åŒ–åæ”¹è¿›è€Œæ¥ï¼Œè·å¾—äº† ILSVRC2014 çš„å† å†›ã€‚

[è®ºæ–‡ç†è§£](/notes/ZFNet.md)

- [VGGNet](https://arxiv.org/abs/1409.1556)

![](/picture/VGG.png)

 ã€ŠVery Deep Convolutional Networks for Large-Scale Image Recognitionã€‹,è™½ç„¶ä¸æ˜¯é‚£å¹´ImageNetå¤§èµ›çš„å† å†›(é‚£å¹´çš„å† å†›æ˜¯GoogLeNet),ä½†æ˜¯VGGNetå¯¹åé¢çš„ResNetï¼ŒInceptionäº§ç”Ÿäº†é‡è¦çš„å½±å“ã€‚

 [è®ºæ–‡ç†è§£](/notes/VGG.md)

- [GoogleNet](https://arxiv.org/abs/1409.4842)å’Œ[Inception V3](https://arxiv.org/abs/1512.00567)

 GoogleNetï¼ˆInception V1ï¼‰å’ŒInception V3:ã€ŠGoing Deeper with Convolutionsã€‹,ã€ŠRethinking the Inception Architecture for Computer Visionã€‹,2014å¹´ImageNetå¤§èµ›å† å†›,Inceptionç»“æ„çš„è®¾è®¡å¾ˆå·§å¦™  ã€‚
 
  [GoogleNet è®ºæ–‡ç†è§£](/notes/GoogLeNet.md)
  
  [Inception V2è®ºæ–‡ç†è§£](/notes/Inception-v2-BN-Inception.md)
  
  [Inception V3è®ºæ–‡ç†è§£](/notes/GoogLeNet-V3.md)
  
  
- [ResNet](https://arxiv.org/abs/1512.03385)


![](https://img-blog.csdnimg.cn/dbce2b4dec894d908b846b39ad40e489.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16)

 ã€ŠDeep Residual Learning for Image Recognitionã€‹ï¼Œç›´æ¥å°†top5é”™è¯¯ç‡é™åˆ°äº†3.57%ï¼ˆGoogLeNet æ˜¯6.66%ï¼‰ï¼Œè¶…è¶Šäº†äººçœ¼ï¼Œæ–‡ä¸­æœ€å¤§çš„äº®ç‚¹å°±æ˜¯æ®‹å·®å—ç»“æ„çš„è®¾è®¡ã€‚
 
  [è®ºæ–‡ç†è§£](/notes/ResNetå’ŒResNeXt.md)
 
- [ResNeXt](https://arxiv.org/abs/1611.05431)


![](https://img-blog.csdnimg.cn/28de62c801bc4839aa72f2474b507507.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16)

 [è®ºæ–‡ç†è§£](/notes/ResNetå’ŒResNeXt.md)


- [DenseNet](https://arxiv.org/abs/1608.06993)

![](https://img-blog.csdnimg.cn/189e3d35498f409d8f4c4e5e94557bca.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16)

[è®ºæ–‡ç†è§£](/notes/DenseNet.md)

* [Inception-v4, Inception ResNet](https://arxiv.org/abs/1602.07261)
    *  [Inception-v4ä»£ç å®ç°](https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v4.py)
    *  [Inception-Resnet-V2ä»£ç å®ç°](https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py)
   
   [Inception V4è®ºæ–‡ç†è§£](/notes/Inception-V4.md)

- [MobileNet v1](https://arxiv.org/abs/1704.04861)


- [MobileNet v2](https://arxiv.org/abs/1704.04861)


- [MobileNet v3](https://arxiv.org/abs/1905.02244)


- [ShuffleNet v1](https://arxiv.org/abs/1707.01083)


- [ShuffleNet v2](https://arxiv.org/abs/1807.11164v1)


- [MnasNet](http://arxiv.org/pdf/1807.11626.pdf)

Google å›¢é˜Ÿæå‡º MnasNet,ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æ€è·¯ï¼Œæå‡ºä¸€ç§èµ„æºçº¦æŸçš„ç»ˆç«¯ CNN æ¨¡å‹çš„è‡ªåŠ¨ç¥ç»ç»“æ„æœç´¢æ–¹æ³•ã€‚

- [EfficientNet_v1](https://arxiv.org/abs/1905.11946v3)


- [EfficientNet_v2](https://arxiv.org/abs/2104.00298)


- [SENet](https://arxiv.org/abs/1709.01507)

ä¸€ä¸ªå¯å«æ¥/æ•´åˆçš„Block ğŸ˜‡ã€‚è®©æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä½¿ç”¨å…¨å±€ä¿¡æ¯æ¥å¢å¼ºæœ‰ç”¨çš„ä¿¡æ¯ï¼ŒåŒæ—¶æŠ‘åˆ¶æ— ç”¨çš„ã€‚

![](/picture/SENet.ong)

[è®ºæ–‡ç†è§£](/notes/SENet.md)


## ç›®æ ‡æ£€æµ‹

RCNNç³»åˆ—ä¸­åŒ…æ‹¬**RCNN, Fast RCNN, Faster RCNN, Mask RCNN**

YOLOç³»åˆ—åŒ…æ‹¬**YOLO v1, YOLO v2, YOLO v3 ä»¥åŠSSD**

- [RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)


- [RCNN](https://arxiv.org/pdf/1311.2524v5.pdf)

  [è®ºæ–‡ç†è§£](/notes/RCNN.md)



- [Fast-RCNN](https://arxiv.org/abs/1504.08083)


- [Faster-RCNN](https://arxiv.org/abs/1506.01497)

RCNNä¸SPPnetä¸€äº›ç¼ºç‚¹ä¸ä¸è¶³ï¼š

- **è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªmulti-stage pipline**. RCNNé¦–å…ˆåœ¨ç»™å®šçš„region proposalä¸Šä½¿ç”¨logæŸå¤±è¿›è¡Œå¾®è°ƒã€‚ç„¶åå°†å·ç§¯ç¥ç»ç½‘ç»œæå–åˆ°çš„ç‰¹å¾è®­ç»ƒSVMåˆ†ç±»å™¨ï¼Œåˆ©ç”¨SVMæ›¿ä»£ç¥ç»ç½‘ç»œåˆ†ç±»ç®—æ³•ä¸­å¸¸ç”¨çš„softmaxã€‚ç¬¬ä¸‰éƒ¨åˆ†å°±æ˜¯å­¦ä¹ æ£€æµ‹æ¡†çš„å›å½’ã€‚

- **è®­ç»ƒéœ€è¦å¤§é‡çš„ç©ºé—´ä¸æ—¶é—´**ï¼Œ ç”±äºè®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦å°†å·ç§¯ç¥ç»ç½‘ç»œæå–çš„ç‰¹å¾å†™å…¥ç£ç›˜ï¼Œå› æ­¤éœ€è¦å¤§é‡çš„ç‰©ç†å­˜å‚¨ç©ºé—´ï¼Œè®­ç»ƒè¿‡ç¨‹ååˆ†ç¼“æ…¢ã€‚

- **æ£€æµ‹è¿‡ç¨‹éå¸¸ç¼“æ…¢**ï¼Œåœ¨æµ‹è¯•æ—¶ï¼Œä»æ¯ä¸ªæµ‹è¯•å›¾åƒä¸­çš„æ¯ä¸ªç›®æ ‡å€™é€‰æ¡†æå–ç‰¹å¾ã€‚

RCNNä¸»è¦å¯¹äºæ¯å¼ å›¾åƒçš„æ¯ä¸ªregion proposaléƒ½è¾“å…¥CNNâ€œç½‘ç»œè¿›è¡Œè®¡ç®—ï¼Œæ²¡æœ‰åŠé€†è¡Œç›¸åº”çš„å…±äº«è®¡ç®—ï¼Œè€ŒSPPnetæ˜¯åˆ©ç”¨å…±äº«å·ç§¯è®¡ç®—çš„æ–¹å¼æ¥åŠ é€ŸRCNNçš„æ£€æµ‹è¿‡ç¨‹ï¼ŒSPPnetå°†æ•´å¼ å›¾ç‰‡è¾“å…¥CNNç½‘ç»œå¾—åˆ°ç‰¹å¾å›¾ï¼Œç„¶ååˆ©ç”¨ç©ºé—´é‡‘å­—å¡”æ± åŒ–ç½‘ç»œå¯¹æ¯ä¸ªregion proposalåŒºåŸŸçš„ç‰¹å¾å›¾è¿›è¡Œå¤„ç†å¾—åˆ°å›ºå®šç»´åº¦çš„ç‰¹å¾å‘é‡ï¼Œç„¶åè®­ç»ƒSVMåˆ†ç±»å™¨ã€‚

ä¸ºè§£å†³ä¸Šè¿°ä¼˜ç‚¹ï¼Œ Fast RCNNä¸»è¦è´¡çŒ®åœ¨äºï¼š

     1.Fast RCNNå…·æœ‰æ›´é«˜çš„ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦    
     2.è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨å¤šä»»åŠ¡çš„æŸå¤±å‡½æ•°
     3.è®­ç»ƒå¯ä»¥æ›´æ–°æ‰€æœ‰ç½‘ç»œå±‚çš„å‚æ•°
     4.ä¸éœ€è¦é¢å¤–çš„ç£ç›˜ç©ºé—´å­˜å‚¨ç‰¹å¾


- [FPN](https://arxiv.org/abs/1612.03144)


- [SSD](https://arxiv.org/abs/1512.02325)


- [RetinaNet](https://arxiv.org/abs/1708.02002)

RetinaNetæ˜¯ç»§SSDå’ŒYOLO V2å…¬å¸ƒåï¼ŒYOLO V3è¯ç”Ÿå‰çš„ä¸€æ¬¾ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œå‡ºè‡ªä½•æºæ˜å¤§ç¥çš„ã€ŠFocal Loss for Dense Object Detectionã€‹ã€‚å…¨æ–‡é’ˆå¯¹ç°æœ‰å•é˜¶æ®µæ³•ï¼ˆone-stage)ç›®æ ‡æ£€æµ‹æ¨¡å‹ä¸­å‰æ™¯(positive)å’ŒèƒŒæ™¯(negatives)ç±»åˆ«çš„ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å«åšFocal Lossçš„æŸå¤±å‡½æ•°ï¼Œç”¨æ¥é™ä½å¤§é‡easy negativesåœ¨æ ‡å‡†äº¤å‰ç†µä¸­æ‰€å æƒé‡ï¼ˆæé«˜hard negativesæ‰€å æƒé‡)ã€‚ä¸ºäº†æ£€æµ‹æå‡ºçš„Focal LossæŸå¤±å‡½æ•°çš„æœ‰æ•ˆæ€§ï¼Œæ‰€ä»¥ä½œè€…å°±é¡ºä¾¿æå‡ºäº†ä¸€ç§ç®€å•çš„æ¨¡å‹RetinaNetã€‚


- [YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf)


- [SPPNet](https://arxiv.org/abs/1406.4729)

github(PyTorch): https://github.com/yueruchen/sppnet-pytorch

ç”¨äºè§†è§‰è¯†åˆ«çš„æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„ç©ºé—´é‡‘å­—å¡”æ± ã€‚SPP-Netçš„æå‡ºä¸€æ–¹é¢è§£å†³äº†å›ºå®šçš„è¾“å…¥å›¾åƒå¤§å°é—®é¢˜ï¼Œå³è¾“å…¥å›¾åƒå¤§å°ä¸å—é™åˆ¶ã€‚å› ä¸ºSPP-Netè§£å†³äº†å…¨è¿æ¥å±‚çš„è¾“å…¥éœ€è¦å›ºå®šç»´åº¦çš„é—®é¢˜ã€‚

é‚£ä¹ˆä¸ºä»€ä¹ˆå…¨è¿æ¥å±‚çš„è¾“å…¥éœ€è¦å›ºå®šç»´åº¦å‘¢ï¼Ÿ

ç­”ï¼šå…¨è¿æ¥å±‚çš„è®¡ç®—å…¶å®ç›¸å½“äºè¾“å…¥çš„ç‰¹å¾å›¾æ•°æ®çŸ©é˜µå’Œå…¨è¿æ¥å±‚æƒå€¼çŸ©é˜µè¿›è¡Œå†…ç§¯ã€‚åœ¨é…ç½®ä¸€ä¸ªç½‘ç»œæ—¶ï¼Œå…¨è¿æ¥å±‚çš„å‚æ•°ç»´åº¦æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥ä¸¤ä¸ªçŸ©é˜µè¦èƒ½å¤Ÿè¿›è¡Œå†…ç§¯ï¼Œåˆ™è¾“å…¥çš„ç‰¹å¾å›¾çš„æ•°æ®çŸ©é˜µç»´æ•°ä¹Ÿéœ€è¦å›ºå®š[X1][X2]ã€‚

RCNNçš„ä¸è¶³ä¹‹å¤„å°±æ˜¯ï¼š
- æ¯ä¸€å¼ å›¾ç‰‡ä¼šæå–å¤§çº¦2åƒä¸ªå€™é€‰åŒºåŸŸï¼ˆregion Proposalï¼‰ï¼Œé’ˆå¯¹æ¯ä¸ªRegion Proposal éƒ½é‡å¤çš„ä½¿ç”¨ CNNæå–ç‰¹å¾ï¼Œå› æ­¤ä¼šåœ¨ç‰¹å¾æå–é˜¶æ®µè€—è´¹å¤§é‡çš„æ—¶é—´ã€‚

- ç”±äºå…¨è¿æ¥å±‚çš„è¾“å…¥ç»´åº¦æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥å¿…é¡» resizeï¼ˆcrop/wrapï¼‰ï¼ŒRegion Proposal æ‰èƒ½è¿›è¡Œç‰¹å¾æå–ï¼Œç»“æœä¼šå¯¼è‡´ä¸¢å¤±å›¾åƒä¿¡æ¯å’Œå›¾ç‰‡å½¢å˜ï¼Œå½±å“ç‰¹å¾æå–çš„å‡†ç¡®ç‡ã€‚

æ‰€ä»¥SPPNet é’ˆå¯¹R-CNNä¸¤å¤„ä¸è¶³åšäº†æ”¹è¿›ï¼š
- å°†Selective Searchçš„Region Proposalä¸æ”¾å…¥CNNè¿›è¡Œç‰¹å¾æå–ï¼Œè€Œæ˜¯ç›´æ¥æŠŠåŸå›¾ç‰‡æ”¾å…¥CNNè¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åæ ¹æ® Region Proposalä½ç½®åœ¨ conv5 çš„ feature map åšä¸€ä¸ªç‰¹å¾æ˜ å°„ï¼Œå†æˆªå–å‡ºæ¯ä¸€ä¸ªRegion Proposal æ‰€æ˜ å°„çš„ feature mapã€‚è¿™æ ·å°±é¿å…äº†é‡å¤æ€§ç”¨ CNN å¯¹æ¯ä¸ª Region Proposal å•ç‹¬æå–ç‰¹å¾ï¼Œå‡å°‘äº†å¤§é‡æ—¶é—´ã€‚

- SPPNet åœ¨åŸæ¥çš„CNNçš„conv5ä¹‹ååŠ å…¥äº† Spatial  Pyramid Pooling layerï¼ˆç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚ï¼‰æ›¿æ¢æ‰åŸæ¥çš„ Pooling5 layerï¼Œç”±äºSPP layer å¯ä»¥æ¥å—ä¸åŒ size çš„feature maps å¹¶è¾“å‡ºç›¸åŒ size çš„feature mapsï¼Œå› æ­¤é¿å…äº† resizeè€Œå¯¼è‡´çš„å›¾ç‰‡å½¢å˜é—®é¢˜ã€‚

ã€€ã€€æ€»ç»“ä¸€ä¸‹ï¼ŒSPP-netçš„åˆè¡·éå¸¸æ˜æ™°ï¼Œå°±æ˜¯å¸Œæœ›ç½‘ç»œå¯¹è¾“å…¥çš„å°ºå¯¸æ›´åŠ çµæ´»ï¼Œåˆ†æåˆ°å·ç§¯ç½‘ç»œå¯¹å°ºå¯¸å¹¶æ²¡æœ‰è¦æ±‚ï¼Œå›ºå®šå°ºå¯¸çš„è¦æ±‚å®Œå…¨æ¥æºäºå…¨è¿æ¥å±‚éƒ¨åˆ†ï¼Œå› è€Œå€ŸåŠ©ç©ºé—´é‡‘å­—å¡”æ± åŒ–çš„æ–¹æ³•æ¥è¡”æ¥ä¸¤è€…ï¼ŒSPP-net åœ¨æ£€æµ‹é¢†åŸŸçš„é‡è¦è´¡çŒ®æ˜¯é¿å…äº†R-CNNçš„å˜å½¢ï¼Œé‡å¤è®¡ç®—ç­‰é—®é¢˜ï¼Œåœ¨æ•ˆæœä¸è¡°å‡çš„æƒ…å†µä¸‹ï¼Œå¤§å¹…æé«˜äº†è¯†åˆ«é€Ÿåº¦ã€‚


## å›¾åƒåˆ†å‰²
- [FCN](https://arxiv.org/abs/1411.4038)

ï¼ˆCVPR 2015 best paper honorable mentionï¼‰å¦‚æœä½ ä¼šåˆ†ç±»ç½‘ç»œï¼Œé‚£ä¹ˆåˆ†å‰²ç½‘ç»œä½ ä¹Ÿå°±ä¼šå¾ˆå¿«æ˜ç™½äº†ï¼Œå› ä¸ºåˆ†ç±»ç½‘ç»œæ˜¯æŠŠä¸€å¼ å›¾é¢„æµ‹æˆä¸€ç±»ï¼Œè€Œåˆ†å‰²ç½‘ç»œæ˜¯æŠŠä¸€å¼ å›¾æ¯ä¸ªåƒç´ éƒ½é¢„æµ‹ä¸€ä¸‹ï¼Œå…¶å®æ˜¯ä¸€æ ·çš„ã€‚

- [R-FCN](https://arxiv.org/abs/1605.06409)

- DeepLabç³»åˆ—ï¼š[DeepLab V1](https://arxiv.org/abs/1412.7062v4)ã€[DeepLab V2](https://arxiv.org/abs/1606.00915)ã€[DeepLab V3](https://arxiv.org/abs/1706.05587)å’Œ[DeepLab V3+](https://arxiv.org/abs/1802.02611)ï¼Œ

 [è®ºæ–‡ç†è§£](/notes/DeepLab.md)

## åŒ»å­¦å½±åƒç›¸å…³
[DeepLung](https://arxiv.org/abs/1801.09555)

 å·¥ç¨‹åœ°å€ï¼šhttps://github.com/wentaozhu/DeepLungã€https://github.com/uci-cbcl/DeepLung

 æå‡ºä¸€ä¸ªå…¨è‡ªåŠ¨çš„è‚ºéƒ¨CTç™Œç—‡è¯Šæ–­ç³»ç»ŸDeepLungã€‚DeepLungåŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼Œç»“èŠ‚æ£€æµ‹(è¯†åˆ«å€™é€‰ç»“èŠ‚ä½ç½®)å’Œåˆ†ç±»ï¼ˆå°†å€™é€‰ç»“èŠ‚åˆ†ç±»ä¸ºè‰¯æ€§æˆ–æ¶æ€§ï¼‰ã€‚è€ƒè™‘åˆ°è‚ºéƒ¨CTæ•°æ®çš„3Dç‰¹æ€§å’ŒåŒè·¯å¾„ç½‘ç»œï¼ˆDPN)çš„å‹ç¼©æ€§ï¼Œè®¾è®¡äº†ä¸¤ä¸ªæ·±åº¦3D DPNåˆ†åˆ«ç”¨äºç»“èŠ‚æ£€æµ‹å’Œå›å½’ã€‚ç‰¹åˆ«åœ°ï¼Œä¸€ä¸ªå¸¦3DåŒè·¯å¾„å—å’ŒU-netå‹ç¼–ç -è§£ç ç»“æ„çš„Faster RCNNæ¥é«˜æ•ˆçš„å­¦ä¹ ç»“èŠ‚ç‰¹å¾ã€‚å¯¹äºç»“èŠ‚åˆ†ç±»ï¼Œæå‡ºä¸€ä¸ªå¸¦3DåŒè·¯å¾„ç½‘ç»œç‰¹å¾çš„æ¢¯åº¦æå‡æœºï¼ˆGBM)ã€‚åœ¨LIDC-IDRIçš„å…¬å¼€æ•°æ®é›†ç»œéªŒè¯äº†ç»“èŠ‚åˆ†ç±»å­ç½‘ï¼Œå–å¾—äº†æ¯”state-of-the-artæ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨åŸºäºå›¾åƒæ¨¡å¼ä¸Šè¶…è¿‡äº†æœ‰ç»éªŒåŒ»ç”Ÿã€‚åœ¨DeepLungç³»ç»Ÿä¸­ï¼Œé¦–å…ˆé€šè¿‡ç»“èŠ‚æ£€æµ‹å­ç½‘ç»œæ£€æµ‹å‡ºå€™é€‰ç»“èŠ‚ï¼Œç„¶åä½¿ç”¨åˆ†ç±»å­ç½‘ç»œåšç»“èŠ‚è¯Šæ–­ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepLungåœ¨LIDC-IDRIæ•°æ®é›†ä¸Šçš„ç»“èŠ‚çº§åˆ«å’Œæ‚£è€…çº§åˆ«è¯Šæ–­æ–¹é¢çš„æ€§èƒ½å‡ä¸ç»éªŒä¸°å¯Œçš„åŒ»ç”Ÿç›¸å½“ã€‚

## å°æ ·æœ¬å­¦ä¹ å’Œå…ƒå­¦ä¹ 
### åŸºäºåº¦é‡å­¦ä¹ çš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•

- [ã€ŠSiamese Neural Networks for One-shot Image Recognitionã€‹](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf)
â€ƒâ€ƒ
ç½‘ç»œåç§°ï¼šSiamese Network
â€ƒ
æ–‡ç« æ¥æºï¼šICML2015

æºç åœ°å€ï¼šå°šæœªå¼€æº


- [ã€ŠMatching Networks for One Shot Learningã€‹](https://arxiv.org/pdf/1606.04080.pdf)
â€ƒâ€ƒ
ç½‘ç»œåç§°ï¼šMatching Network
â€ƒâ€ƒ
æ–‡ç« æ¥æºï¼šNIPS2016

æºç åœ°å€ï¼šå°šæœªå¼€æº
  
  
- [ã€ŠPrototypical Networks for Few-shot Learningã€‹](https://arxiv.org/pdf/1703.05175.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šPrototypical Network
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2017

  [æºç åœ°å€](https://github.com/jakesnell/prototypical-networks)
  
- [ã€ŠLearning to Compare: Relation Network for Few-Shot Learningã€‹](https://arxiv.org/pdf/1711.06025.pdf)
 
 
 â€ƒâ€ƒç½‘ç»œåç§°ï¼šRelation Network
â€ƒâ€ƒ 
â€ƒâ€ƒ 
â€ƒâ€ƒ æ–‡ç« æ¥æºï¼šCVPR2018
â€ƒâ€ƒ 
â€ƒâ€ƒ
â€ƒâ€ƒ [æºç åœ°å€](https://github.com/lzrobots/DeepEmbeddingModel_ZSL)
â€ƒâ€ƒ 
-  [ã€ŠFinding Task-Relevant Features for Few-Shot Learning by Category Traversalã€‹](https://arxiv.org/pdf/1905.11116.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šCTM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/Clarifai/few-shot-ctm)

- [ã€ŠVariational Prototyping-Encoder: One-Shot Learning with Prototypical Imagesã€‹](https://arxiv.org/pdf/1904.08482.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šVPE
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/mibastro/VPE)

- [ã€ŠRepMet: Representative-based metric learning for classification and few-shot object detectionã€‹](https://arxiv.org/pdf/1806.04728.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šRepMet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
8. [Revisiting Local Descriptor based Image-to-Class Measure for Few-shot Learningã€‹](https://arxiv.org/pdf/1903.12290v1.pdf)â€ƒâ€ƒ

â€ƒâ€ƒç½‘ç»œåç§°ï¼šDN4
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019

  [æºç åœ°å€](https://github.com/WenbinLee/DN4)
â€ƒâ€ƒ
9. [ã€ŠFew-Shot Learning with Localization in Realistic Settingsã€‹](https://arxiv.org/pdf/1904.08502v1.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/daviswer/fewshotlocal)
â€ƒâ€ƒ
10. [ã€ŠDense Classification and Implanting for Few-Shot Learningã€‹](https://arxiv.org/pdf/1903.05050.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
11. [ã€ŠTADAM: Task dependent adaptive metric for improved few-shot learningã€‹](https://arxiv.org/pdf/1805.10123.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šTADAM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2018
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/ElementAI/TADAM)
â€ƒâ€ƒ
12. [ã€ŠPower Normalizing Second-order Similarity Network for Few-shot Learningã€‹](https://arxiv.org/abs/1811.04167v1.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šSoSN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šWACV2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
13. [ã€ŠFew-Shot Learning with Metric-Agnostic Conditional Embeddingsã€‹](https://arxiv.org/pdf/1802.04376v1.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šMACO
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2018
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
14. [ã€ŠImproved Few-Shot Visual Classificationã€‹](https://arxiv.org/pdf/1912.03432.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSimple CNAPS
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/peymanbateni/simple-cnaps)
â€ƒâ€ƒ
15. [ã€ŠDeepEMD: Few-Shot Image Classification with Differentiable Earth Moverâ€™s Distance and Structured Classifierã€‹](https://arxiv.org/abs/2003.06777v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šDeepEMD
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
16. [ã€ŠBoosting Few-Shot Learning with Adaptive Margin Lossã€‹](https://arxiv.org/pdf/2005.13826.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šCRAMLå’ŒTRAML
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
17. [ã€ŠAdaptive Subspaces for Few-Shot Learningã€‹](http://openaccess.thecvf.com/content_CVPR_2020/papers/Simon_Adaptive_Subspaces_for_Few-Shot_Learning_CVPR_2020_paper.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šDSN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/chrysts/dsn_fewshot)
â€ƒâ€ƒ
18. [ã€ŠLearning Embedding Adaptation for Few-Shot Learningã€‹](https://arxiv.org/pdf/1812.03664v2.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šFEAT

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/Sha-Lab/FEAT)
â€ƒâ€ƒ
19. [ã€ŠTapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learningã€‹](https://arxiv.org/pdf/1905.06549v1.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šTapNet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
20. [ã€ŠFew-Shot Learning with Embedded Class Models and Shot-Free Meta Trainingã€‹](https://arxiv.org/pdf/1905.04398v1.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šShot-Free
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV 2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
21. [ã€ŠFew-Shot Learning with Graph Neural Networksã€‹](https://arxiv.org/pdf/1711.04043.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šGNN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2018

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/vgsatorras/few-shot-gnn)
â€ƒâ€ƒ
22. [ã€ŠTransductive Episodic-Wise Adaptive Metric for Few-Shot Learningã€‹](https://arxiv.org/pdf/1910.02224.pdf)]

â€ƒâ€ƒç½‘ç»œåç§°ï¼šTEAM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
23. [ã€ŠFew-Shot Learning with Global Class Representationsã€‹](https://arxiv.org/pdf/1908.05257.pdf)
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
24. [ã€ŠPARN: Position-Aware Relation Networks for Few-Shot Learningã€‹](https://arxiv.org/pdf/1909.04332.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šPARN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
25. [ã€ŠEdge-Labeling Graph Neural Network for Few-shot Learningã€‹](https://arxiv.org/pdf/1905.01436.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šEGNN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/khy0809/fewshot-egnn)
â€ƒâ€ƒ
26. [ã€ŠDPGN: Distribution Propagation Graph Network for Few-shot Learningã€‹](https://arxiv.org/pdf/2003.14247.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šDPGN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/megvii-research/DPGN)
â€ƒâ€ƒ
27. [ã€ŠAdaptive Cross-Modal Few-shot Learningã€‹](https://arxiv.org/pdf/1902.07104.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šAM3
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
28. [ã€ŠSelf-attention relation network for few-shot learningã€‹](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8794911)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSARN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICMEW2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
29. [ã€ŠPrincipal characteristic networks for few-shot learningã€‹](https://www.sciencedirect.com/science/article/pii/S1047320319300574?via%3Dihub)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šPC-Net
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šJournal Of Visual Communication And Image Representation

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
30. [ã€ŠInstance-Level Embedding Adaptation for Few-Shot Learningã€‹](https://ieeexplore.ieee.org/document/8672561/)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šAAM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šIEEE Access

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
31. [ã€ŠGenerative Adversarial Residual Pairwise Networks for One Shot Learning ã€‹](http://export.arxiv.org/pdf/1703.08033)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSRPN

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
32. [ã€ŠDeep Triplet Ranking Networks for One-Shot Recognitionã€‹](https://arxiv.org/pdf/1804.07275.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šTriplet Ranking Networks

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
33. [ã€ŠLarge Margin Few-Shot Learningã€‹](https://arxiv.org/pdf/1807.02872.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šL-GNN/L-PN

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
34. [ã€ŠDistribution Consistency Based Covariance Metric Networks for Few-Shot Learningã€‹](https://aaai.org/ojs/index.php/AAAI/article/view/4885/4758)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šCovaMNet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šAAAI 2019

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/WenbinLee/CovaMNet)
â€ƒâ€ƒ
35. [ã€ŠRelationNet2: Deep Comparison Columns for Few-Shot Learningã€‹](https://arxiv.org/pdf/1811.07100v3.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šDCN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šIJCNN2020

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/zhangxueting/DCN)

### åŸºäºå‚æ•°ä¼˜åŒ–çš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•

1. [ã€ŠOptimization as A Model for Few-shot Learningã€‹](https://openreview.net/pdf?id=rJY0-Kcll)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMeta-Learner LSTM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2017

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/twitter/meta-learning-lstm)
â€ƒâ€ƒ
2. [ã€ŠModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networksã€‹](https://arxiv.org/pdf/1703.03400.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMAML
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2017
â€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/vieozhu/MAML-TensorFlow-1)
â€ƒâ€ƒ
3. [ã€ŠMeta-SGD: Learning to Learn Quickly for Few-Shot Learningã€‹](https://arxiv.org/pdf/1707.09835.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMeta-SGD
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠTask-Agnostic Meta-Learning for Few-shot Learningã€‹](https://arxiv.org/pdf/1805.07722.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTAML
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ
â€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒ
5. [ã€ŠOn First-Order Meta-Learning Algorithmsã€‹](https://arxiv.org/pdf/1803.02999v3.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šReptile

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
6. [ã€ŠDeep Meta-Learning: Learning to Learn in the Concept Spaceã€‹](https://arxiv.org/abs/1802.03596.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šDEML
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
7. [ã€ŠMeta-Learning of Neural Architectures for Few-Shot Learningã€‹](https://arxiv.org/abs/1911.11090.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMetaNAS
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
8. [ã€ŠAttentive Weights Generation for Few Shot Learning via Information Maximizationã€‹](http://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Attentive_Weights_Generation_for_Few_Shot_Learning_via_Information_Maximization_CVPR_2020_paper.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šAWGIM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/Yiluan/AWGIM)
â€ƒâ€ƒ
9. [ã€ŠMeta-learning with Latent Embedding Optimizationã€‹](https://arxiv.org/pdf/1807.05960.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šLEO
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/deepmind/leo)
â€ƒâ€ƒ
10. [ã€ŠMeta-learning with differentiable closed-form solversã€‹](https://arxiv.org/pdf/1805.08136v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šR2-D2/LR-D2
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/bertinetto/r2d2)
â€ƒâ€ƒ
11. [ã€ŠMetAdapt: Meta-Learned Task-Adaptive Architecture for Few-Shot Classificationã€‹](https://arxiv.org/pdf/1912.00412.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMetAdapt
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
12. [ã€ŠGradient-Based Meta-Learning with Learned Layerwise Metric and Subspaceã€‹](https://arxiv.org/pdf/1801.05558v3.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šT-net/MT-net
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2018

â€ƒâ€ƒ[æºç åœ°å€](https://github.com/yoonholee/MT-net)
â€ƒâ€ƒ
13. [ã€ŠAuto-Meta: Automated Gradient Based Meta Learner Searchã€‹](https://arxiv.org/pdf/1806.06927.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šAuto-Meta
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº

### åŸºäºå¤–éƒ¨è®°å¿†çš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•

1. [ã€ŠMeta-Learning with Memory-Augmented Neural Networksã€‹](https://arxiv.org/pdf/1605.06065v1.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMANN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2016
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
2. [ã€ŠMeta Networksã€‹](https://arxiv.org/pdf/1703.00837.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMetaNet
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICML2017

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
3. [ã€ŠLearning to remember rare eventsã€‹](https://arxiv.org/pdf/1703.03129.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2017
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠMemory Matching Networks for One-Shot Image Recognitionã€‹](https://arxiv.org/pdf/1804.08281.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMM-Net
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
5. [ã€ŠDynamic Few-Shot Visual Learning without Forgettingã€‹](https://arxiv.org/abs/1804.09458.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2018
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/gidariss/FewShotWithoutForgetting)

### åŸºäºæ•°æ®å¢å¼ºçš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•

1. [ã€ŠLow-Shot Visual Recognition by Shrinking and Hallucinating Featuresã€‹](https://arxiv.org/pdf/1606.02819v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSGM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2017
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/facebookresearch/low-shot-shrink-hallucinate)
â€ƒâ€ƒ
2. [ã€ŠMeta-learning for semi-supervised few-shot classificationã€‹](https://arxiv.org/pdf/1906.00562.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2018
â€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/renmengye/few-shot-ssl-public)
â€ƒâ€ƒ
3. [ã€ŠLaSO: Label-Set Operations networks for multi-label few-shot learningã€‹](https://arxiv.org/pdf/1902.09811v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šLaSONet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠImage Deformation Meta-Networks for One-Shot Learningã€‹](https://arxiv.org/pdf/1905.11641v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šIDeMe-Net
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/tankche1/IDeMe-Net)
â€ƒâ€ƒ
5. [ã€ŠFew-shot Learning via Saliency-guided Hallucination of Samplesã€‹](https://arxiv.org/pdf/1904.03472v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSalNet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
6. [ã€ŠLow-Shot Learning from Imaginary Dataã€‹](https://arxiv.org/pdf/1801.05401v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šPMN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
7. [ã€ŠInstance Credibility Inference for Few-Shot Learningã€‹](http://arxiv.org/abs/2003.11853.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šICI
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šhttps://github.com/Yikai-Wang/ICI-FSL
â€ƒâ€ƒ
8. [ã€ŠAdversarial Feature Hallucination Networks for Few-Shot Learningã€‹](https://arxiv.org/pdf/2003.13193.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šAFHN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
9. [ã€Šâˆ†-encoder: an effective sample synthesis method for few-shot object recognitionã€‹](https://arxiv.org/pdf/1806.04734.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šâˆ†-encoder
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2018
â€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/EliSchwartz/DeltaEncoder)

### åŸºäºè¯­ä¹‰ä¿¡æ¯çš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•
1. [ã€ŠLarge-Scale Few-Shot Learning: Knowledge Transfer With Class Hierarchyã€‹]()https://www.researchgate.net/profile/Zhiwu_Lu2/publication/333602008_Large-Scale_Few-Shot_Learning_Knowledge_Transfer_With_Class_Hierarchy/links/5cf61bffa6fdcc847502e9de/Large-Scale-Few-Shot-Learning-Knowledge-Transfer-With-Class-Hierarchy.pdf
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
2. [ã€ŠGeneralized Zero- and Few-Shot Learning via Aligned Variational Autoencodersã€‹](https://arxiv.org/pdf/1812.01784.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šCADA-VAE
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/edgarschnfld/CADA-VAE-PyTorch)
â€ƒâ€ƒ
3. [ã€ŠTAFE-Net: Task-Aware Feature Embeddings for Low Shot Learningã€‹](https://arxiv.org/pdf/1904.05967.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTAFE-Net
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šhttps://github.com/ucbdrive/tafe-net
â€ƒâ€ƒ
4. [ã€ŠBaby Steps Towards Few-Shot Learning with Multiple Semanticsã€‹](https://arxiv.org/pdf/1906.01905.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMultiple-Semantics
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
5. [ã€ŠSemantic Feature Augmentation in Few-shot Learningã€‹](https://arxiv.org/pdf/1804.05298v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šDual-TriNet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šECCV2018
â€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/tankche1/Semantic-Feature-Augmentation-in-Few-shot-Learning)

6. [ã€ŠLearning Compositional Representations for Few-Shot Recognitionã€‹](https://arxiv.org/pdf/1812.09213.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šcomp
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019
â€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://sites.google.com/view/comprepr/home)
â€ƒâ€ƒ
7. [ã€ŠFew-Shot Image Recognition with Knowledge Transferã€‹](http://openaccess.thecvf.com/content_ICCV_2019/papers/Peng_Few-Shot_Image_Recognition_With_Knowledge_Transfer_ICCV_2019_paper.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šKTN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº

### å…¶ä»–ç±»å‹çš„å°æ ·æœ¬å­¦ä¹ ç®—æ³•
1. [ã€ŠActive One-shot Learningã€‹](https://arxiv.org/pdf/1702.06559.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2016
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
2. [ã€ŠSpot and Learn: A Maximum-Entropy Patch Sampler for Few-Shot Image Classificationã€‹](http://openaccess.thecvf.com/content_CVPR_2019/papers/Chu_Spot_and_Learn_A_Maximum-Entropy_Patch_Sampler_for_Few-Shot_Image_CVPR_2019_paper.pdf?source=post_page)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
3. [ã€ŠMeta-Learning with Temporal Convolutionsã€‹/ã€ŠA simple neural attentive meta-learnerã€‹](https://arxiv.org/pdf/1707.03141v2.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTCML/SNAIL
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2018
â€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠMeta-Transfer Learning for Few-Shot Learningã€‹](https://arxiv.org/pdf/1812.02391v2.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMTL
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/yaoyao-liu/meta-transfer-learning)
â€ƒâ€ƒ
5. [ã€ŠLearning to propagate labels: Transductive propagation network for few-shot learningã€‹](http://arxiv.org/abs/1805.10002.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTPN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
6. [ã€ŠFew-Shot Class-Incremental Learningã€‹](https://arxiv.org/pdf/2004.10956.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTOPIC
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
7. [ã€ŠLearning to Select Base Classes for Few-shot Classificationã€‹](https://arxiv.org/abs/2004.00315.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
8. [ã€ŠTransMatch: A Transfer-Learning Scheme for Semi-Supervised Few-Shot Learningã€‹](https://arxiv.org/pdf/1912.09033.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šTransMatch
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
9. [ã€ŠA closer look at few-shot classificationã€‹](https://arxiv.org/pdf/1904.04232v1.pdf)

â€ƒâ€ƒç½‘ç»œåç§°ï¼šCloserLook
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/wyharveychen/CloserLookFewShot)
â€ƒâ€ƒ
10. [ã€ŠLow-Shot Learning with Imprinted Weightsã€‹](https://arxiv.org/pdf/1712.07136.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šImprinting
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR 2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
11. [ã€ŠBoosting Few-Shot Visual Learning with Self-Supervisionã€‹](ttps://arxiv.org/pdf/1906.05186v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV 2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
12. [ã€ŠDiversity with Cooperation: Ensemble Methods for Few-Shot Classificationã€‹](https://arxiv.org/pdf/1903.11341v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šRobust-dist
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
13. [ã€ŠSimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learningã€‹](https://arxiv.org/pdf/1911.04623.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šSimpleShot
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/mileyan/simple_shot)
â€ƒâ€ƒ
14. [ã€ŠFew-shot Classification via Adaptive Attentionã€‹](https://arxiv.org/pdf/2008.02465.pdf)

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
15. [ã€ŠFew-Shot Image Recognition by Predicting Parameters from Activationsã€‹](http://arxiv.org/abs/1706.03466.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šPPA
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR 2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
16. [ã€ŠGenerating Classification Weights with GNN Denoising Autoencoders for Few-Shot Learningã€‹](https://arxiv.org/pdf/1905.01102v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šDAE
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/gidariss/wDAE_GNN_FewShot)
â€ƒâ€ƒ
17. [ã€ŠFew-Shot Learning Through an Information Retrieval Lensã€‹](https://arxiv.org/pdf/1707.02610.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šmAP-SSVMï¼ŒmAP-DLM
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šNIPS2017
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº

### å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ç®—æ³•
1. [ã€ŠOne-Shot Learning for Semantic Segmentationã€‹](https://arxiv.org/pdf/1709.03410.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šBMVC2017
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/lzzcd001/OSLSM)
â€ƒâ€ƒ
2. [ã€ŠConditional networks for few-shot semantic segmentationã€‹](https://openreview.net/pdf?id=SkMjFKJwG)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šco-FCN
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICLR2018
â€ƒâ€ƒ
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
3. [ã€ŠCANet: Class-Agnostic Segmentation Networks with Iterative Refinement and Attentive Few-Shot Learningã€‹](https://arxiv.org/pdf/1903.02351.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šCANet
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠPANet: Few-Shot Image Semantic Segmentation with Prototype Alignmentã€‹](https://arxiv.org/pdf/1908.06391.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šPANet
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº

### å°æ ·æœ¬ç›®æ ‡æ£€æµ‹ç®—æ³•
1. [ã€ŠLSTD: A Low-Shot Transfer Detector for Object Detectionã€‹](https://arxiv.org/pdf/1803.01529.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šLSTD
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šAAAI2018

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
2. [ã€ŠFew-Example Object Detection with Model Communicationã€‹](https://arxiv.org/pdf/1706.08249.pdf)
â€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMSPLD
â€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šTPAMI2018
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
3. [ã€ŠIncremental Few-Shot Object Detectionã€‹](https://arxiv.org/pdf/2003.04668.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šONCE
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
4. [ã€ŠFew-Shot Object Detection with Attention-RPN and Multi-Relation Detectorã€‹](https://arxiv.org/abs/1908.01998.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šCVPR2020
â€ƒâ€ƒ
â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
5. [ã€ŠFew-shot Object Detection via Feature Reweightingã€‹](https://arxiv.org/abs/1812.01866.pdf)

â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019

â€ƒâ€ƒæºç åœ°å€ï¼šå°šæœªå¼€æº
â€ƒâ€ƒ
6.[ã€ŠMeta R-CNN : Towards General Solver for Instance-level Low-shot Learningã€‹](http://arxiv.org/abs/1909.13032v1.pdf)
â€ƒâ€ƒ
â€ƒâ€ƒç½‘ç»œåç§°ï¼šMeta R-CNN
â€ƒâ€ƒ
â€ƒâ€ƒæ–‡ç« æ¥æºï¼šICCV2019
â€ƒâ€ƒ
â€ƒâ€ƒ[æºç åœ°å€](https://github.com/yanxp/MetaR-CNN)

 
## CVä¸­çš„Attentionæœºåˆ¶
- [Transformer](https://arxiv.org/abs/1706.03762)

Transformerç”±è®ºæ–‡ã€ŠAttention is All You Needã€‹æå‡ºï¼Œç°åœ¨æ˜¯è°·æ­Œäº‘TPUæ¨èçš„å‚è€ƒæ¨¡å‹ã€‚

**Motivation**:
1. é attentionæœºåˆ¶ï¼Œä¸ä½¿ç”¨rnnå’Œcnnï¼Œå¹¶è¡Œåº¦é«˜
2. é€šè¿‡attentionï¼ŒæŠ“é•¿è·ç¦»ä¾èµ–å…³ç³»æ¯”RNNå¼º

**åˆ›æ–°ç‚¹**ï¼š

1. é€šè¿‡self-attentionï¼Œè‡ªå·±å’Œè‡ªå·±åšattentionï¼Œä½¿å¾—æ¯ä¸ªè¯éƒ½æœ‰å…¨å±€çš„è¯­ä¹‰ä¿¡æ¯ï¼ˆé•¿ä¾èµ–

2. ç”±äº Self-Attention æ˜¯æ¯ä¸ªè¯å’Œæ‰€æœ‰è¯éƒ½è¦è®¡ç®— Attentionï¼Œæ‰€ä»¥ä¸ç®¡ä»–ä»¬ä¸­é—´æœ‰å¤šé•¿è·ç¦»ï¼Œæœ€å¤§çš„è·¯å¾„é•¿åº¦ä¹Ÿéƒ½åªæ˜¯ 1ã€‚å¯ä»¥æ•è·é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚

3. æå‡ºmulti-head attentionï¼Œå¯ä»¥çœ‹æˆattentionçš„ensembleç‰ˆæœ¬ï¼Œä¸åŒheadå­¦ä¹ ä¸åŒçš„å­ç©ºé—´è¯­ä¹‰ã€‚

- [Vision Transformer(ViT)](https://openreview.net/pdf?id=YicbFdNTTy)

1. ä½œè€…å°è¯•å°†Transformerç»“æ„ç›´æ¥åº”ç”¨åˆ°å›¾åƒä¸Šï¼Œå³å°†ä¸€å¼ å›¾åƒåˆ†å‰²æˆå¤šä¸ªpatchesï¼Œè¿™äº›patchesçœ‹ä½œæ˜¯NLPçš„tokens (words)ï¼Œç„¶åå¯¹æ¯ä¸ªpatchesåšä¸€ç³»åˆ—linear embeddingæ“ä½œä¹‹åä½œä¸ºTransformerçš„inputã€‚

2. ä½†ä½œè€…å‘ç°ï¼Œè¯¥æ–¹æ³•åœ¨ImageNetè¿™ç§ mid-sized  æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œaccè¦æ¯”åŒç­‰å¤§å°çš„ResNetsä½ä¸€ç‚¹ã€‚åŸå› å¯èƒ½æ˜¯ï¼ŒTransformersç¼ºå°‘CNNå›ºæœ‰çš„inductive biasesï¼Œæ¯”å¦‚è¯´å¹³ç§»ä¸å˜æ€§å’Œå±€éƒ¨æ€§ï¼Œå› æ­¤åœ¨è®­ç»ƒé›†ä¸å¤Ÿå……è¶³çš„æ—¶å€™ï¼Œæ³›åŒ–æ€§ä¸å¥½ã€‚
 
3. ä½†ä½œè€…å‘ç°å½“åœ¨æ›´å¤§è§„æ¨¡çš„æ•°æ®é›†ä¸Špretrainåï¼Œå†transfer åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼ŒTransformerå´å¯ä»¥è¡¨ç°å¾—æ›´å¥½ã€‚

 [è®ºæ–‡ç†è§£](/notes/ViT.md)
 
- [Swin Transformer](https://arxiv.org/abs/2103.14030)

ä»£ç ï¼š[è¯­ä¹‰åˆ†å‰²](https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation)ï¼Œ[å›¾åƒåˆ†ç±»](https://github.com/microsoft/Swin-Transformer)ï¼Œ[ç›®æ ‡æ£€æµ‹](https://github.com/SwinTransformer/Swin-Transformer-Object-Detection)

- [BoTNet](https://arxiv.org/abs/2101.11605)

 è¯¥æ¶æ„å°†è‡ªæ³¨æ„åŠ›çº³å…¥äº†å¤šç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬å›¾åƒåˆ†ç±»ï¼Œç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ã€‚é€šè¿‡ä»…åœ¨ResNetçš„æœ€åä¸‰ä¸ªbottleneck blocksä¸­ç”¨å…¨å±€è‡ªæ³¨æ„åŠ›æ›¿æ¢ç©ºé—´å·ç§¯ï¼Œå¹¶ä¸”ä¸è¿›è¡Œå…¶ä»–ä»»ä½•æ›´æ”¹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®ä¾‹åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹æ–¹é¢æ˜¾è‘—æ”¹å–„äº†åŸºçº¿ï¼ŒåŒæ—¶è¿˜å‡å°‘äº†å‚æ•°ï¼Œä»è€Œä½¿å»¶è¿Ÿæœ€å°åŒ–ã€‚
 
 [è®ºæ–‡ç†è§£](/notes/BoTNet.md)

## å…¶ä»–

- [DeepID2+](https://arxiv.org/abs/1412.1265)

 ã€ŠDeeply learned face representations are sparse, selective, and robustã€‹ä¸ºä»€ä¹ˆè¦æ¨èè¿™ç¯‡è®ºæ–‡å‘¢ï¼Ÿäººè„¸è¯†åˆ«é¢†åŸŸï¼ŒDeepIDå¤§åå¦‚é›·è´¯è€³ï¼Œä¸DeepID,DeepID2ä¸åŒçš„æ˜¯ï¼Œè¿™ç¯‡è®ºæ–‡å¹¶ä¸æ˜¯å•çº¯è®²äººè„¸è¯†åˆ«ï¼Œè®ºæ–‡æ·±å…¥åˆ†æäº†CNNçš„å†…éƒ¨ç»“æ„ï¼Œè¯•å›¾ä»ç†è®ºä¸Šè§£é‡ŠCNNå¼ºå¤§çš„ç‰¹å¾æå–èƒ½å’Œåˆ†ç±»è¯†åˆ«èƒ½åŠ›ï¼Œè¿™æ˜¯å­¦è€…ç¬¬ä¸€æ¬¡è¯•å›¾å»æ¢ç´¢CNNçš„æœ¬è´¨å±æ€§ï¼Œçœ‹å®Œè¿™ç¯‡è®ºæ–‡ï¼Œç›¸ä¿¡å¯¹CNNä¼šæœ‰æ›´æ·±å…¥çš„äº†è§£ã€‚

- [GPT-3](https://arxiv.org/abs/2005.14165)

 githubé“¾æ¥ï¼šhttps://github.com/openai/gpt-3

 å¯¹äºæ‰€æœ‰ä»»åŠ¡ï¼Œåº”ç”¨GPT-3æ— éœ€è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°æˆ–å¾®è°ƒï¼Œè€Œä»…é€šè¿‡ä¸æ¨¡å‹çš„æ–‡æœ¬äº¤äº’æŒ‡å®šä»»åŠ¡å’Œå°‘é‡æ¼”ç¤ºå³å¯ã€‚ GPT-3åœ¨è®¸å¤šNLPæ•°æ®é›†ä¸Šå‡å…·æœ‰å‡ºè‰²çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ç¿»è¯‘ï¼Œé—®é¢˜è§£ç­”å’Œå®Œå½¢å¡«ç©ºä»»åŠ¡ï¼Œä»¥åŠä¸€äº›éœ€è¦å³æ—¶æ¨ç†æˆ–é¢†åŸŸé€‚åº”çš„ä»»åŠ¡



## å¸¸ç”¨æ•°æ®é›†

* [ImageNet](#ImageNett)
* [COCO](#COCO)
* [CIFAR-10](#CIFAR-10)
* [PASCAL VOC](#PASCAL-VOC)

### [ImageNet](https://paperswithcode.com/dataset/imagenet)
 
 ImageNetæ•°æ®é›†åŒ…å«14,197,122å¼ æ ¹æ®WordNetå±‚æ¬¡ç»“æ„æ ‡æ³¨çš„å›¾åƒã€‚è‡ª2010å¹´ä»¥æ¥ï¼Œè¯¥æ•°æ®é›†è¢«ç”¨äºImageNetå¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›ï¼ˆILSVRCï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå›¾åƒåˆ†ç±»å’Œç‰©ä½“æ£€æµ‹çš„åŸºå‡†ã€‚å…¬å¼€å‘å¸ƒçš„æ•°æ®é›†åŒ…å«ä¸€ç»„äººå·¥æ ‡æ³¨çš„è®­ç»ƒå›¾åƒã€‚ä¸€ç»„æµ‹è¯•å›¾åƒä¹Ÿè¢«å‘å¸ƒï¼Œä½†ä¸åŒ…æ‹¬äººå·¥æ³¨é‡Šã€‚ILSVRCçš„æ³¨é‡Šåˆ†ä¸ºä¸¤ç±»ä¹‹ä¸€ã€‚(1)å›¾åƒçº§åˆ«çš„æ³¨é‡Šï¼Œå³å¯¹å›¾åƒä¸­æ˜¯å¦å­˜åœ¨ä¸€ä¸ªç‰©ä½“ç±»åˆ«çš„äºŒè¿›åˆ¶æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼Œ"è¿™å¹…å›¾åƒä¸­æœ‰æ±½è½¦"ï¼Œä½† "æ²¡æœ‰è€è™"ï¼Œä»¥åŠ(2)ç‰©ä½“çº§åˆ«çš„æ³¨é‡Šï¼Œå³å¯¹å›¾åƒä¸­ä¸€ä¸ªç‰©ä½“å®ä¾‹çš„ç´§å¯†è¾¹ç•Œæ¡†å’Œç±»åˆ«æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼Œ"æœ‰ä¸€æŠŠèºä¸åˆ€ï¼Œä¸­å¿ƒä½ç½®æ˜¯(20,25)ï¼Œå®½åº¦ä¸º50åƒç´ ï¼Œé«˜åº¦ä¸º30åƒç´ "ã€‚ImageNeté¡¹ç›®ä¸æ‹¥æœ‰å›¾åƒçš„ç‰ˆæƒï¼Œå› æ­¤åªæä¾›å›¾åƒçš„ç¼©ç•¥å›¾å’ŒURLã€‚
 
 - éç©ºçš„WordNetåŒä¹‰è¯æ€»æ•°ï¼š21841ä¸ª
 - å›¾åƒæ€»æ•°ã€‚14197122
 - æœ‰è¾¹ç•Œç›’æ³¨é‡Šçš„å›¾åƒæ•°é‡ã€‚1,034,908
 - å…·æœ‰SIFTç‰¹å¾çš„åŒä¹‰è¯ç»„æ•°é‡ã€‚1000
 - å…·æœ‰SIFTç‰¹å¾çš„å›¾åƒæ•°é‡ã€‚1.2ç™¾ä¸‡

### [COCO](https://paperswithcode.com/dataset/coco)

 MS COCOï¼ˆMicrosoft Common Objects in Contextï¼‰æ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„ç‰©ä½“æ£€æµ‹ã€åˆ†å‰²ã€å…³é”®ç‚¹æ£€æµ‹å’Œå­—å¹•æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ç”±328Kå›¾åƒç»„æˆã€‚

 åˆ†å‰²ã€‚MS COCOæ•°æ®é›†çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬æ˜¯åœ¨2014å¹´å‘å¸ƒçš„ã€‚å®ƒåŒ…å«16.4ä¸‡å¼ å›¾åƒï¼Œåˆ†ä¸ºè®­ç»ƒï¼ˆ83Kï¼‰ã€éªŒè¯ï¼ˆ41Kï¼‰å’Œæµ‹è¯•ï¼ˆ41Kï¼‰é›†ã€‚2015å¹´ï¼Œåˆå‘å¸ƒäº†81Kçš„æµ‹è¯•é›†ï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»¥å‰çš„æµ‹è¯•å›¾åƒå’Œ40Kçš„æ–°å›¾åƒã€‚

 æ ¹æ®ç¤¾åŒºçš„åé¦ˆï¼Œåœ¨2017å¹´ï¼Œè®­ç»ƒ/éªŒè¯çš„åˆ†å‰²ä»83K/41Kæ”¹ä¸º118K/5Kã€‚æ–°çš„åˆ†å‰²ä½¿ç”¨ç›¸åŒçš„å›¾åƒå’Œæ³¨é‡Šã€‚2017å¹´çš„æµ‹è¯•é›†æ˜¯2015å¹´æµ‹è¯•é›†çš„41Kå›¾åƒçš„ä¸€ä¸ªå­é›†ã€‚æ­¤å¤–ï¼Œ2017å¹´çš„ç‰ˆæœ¬åŒ…å«ä¸€ä¸ªæ–°çš„æœªæ³¨é‡Šçš„æ•°æ®é›†ï¼Œå³123000å¼ å›¾åƒã€‚

æ³¨é‡Šã€‚è¯¥æ•°æ®é›†æœ‰ä»¥ä¸‹æ³¨è§£

- ç‰©ä½“æ£€æµ‹ï¼šè¾¹ç•Œæ¡†å’Œæ¯ä¸ªå®ä¾‹çš„åˆ†å‰²æ©ç ï¼Œæœ‰80ä¸ªç‰©ä½“ç±»åˆ«ã€‚
- è¯´æ˜ï¼šå›¾åƒçš„è‡ªç„¶è¯­è¨€æè¿°ï¼ˆè§MS COCOè¯´æ˜ï¼‰ã€‚
- å…³é”®ç‚¹æ£€æµ‹ï¼šåŒ…å«è¶…è¿‡200,000å¼ å›¾ç‰‡å’Œ250,000ä¸ªæ ‡æœ‰å…³é”®ç‚¹çš„äººç‰©å®ä¾‹ï¼ˆ17ä¸ªå¯èƒ½çš„å…³é”®ç‚¹ï¼Œå¦‚å·¦çœ¼ã€é¼»å­ã€å³è‡€ã€å³è„šè¸ï¼‰ã€‚
- ä¸œè¥¿å›¾åƒåˆ†å‰²--æ¯åƒç´ åˆ†å‰²æ©ç æœ‰91ä¸ªä¸œè¥¿ç±»åˆ«ï¼Œå¦‚è‰ã€å¢™ã€å¤©ç©ºï¼ˆè§MS COCO Stuffï¼‰ã€‚
- å…¨æ™¯ï¼šå…¨åœºæ™¯åˆ†å‰²ï¼Œæœ‰80ä¸ªäº‹ç‰©ç±»åˆ«ï¼ˆå¦‚äººã€è‡ªè¡Œè½¦ã€å¤§è±¡ï¼‰å’Œ91ä¸ªä¸œè¥¿ç±»åˆ«çš„å­é›†ï¼ˆè‰ã€å¤©ç©ºã€é“è·¯ï¼‰ã€‚
- å¯†é›†å§¿æ€ï¼šè¶…è¿‡39,000å¼ å›¾ç‰‡å’Œ56,000ä¸ªäººç‰©å®ä¾‹è¢«æ ‡æ³¨äº†å¯†é›†å§¿æ€æ³¨é‡Š--æ¯ä¸ªè¢«æ ‡æ³¨çš„äººç‰©éƒ½è¢«æ ‡æ³¨äº†ä¸€ä¸ªå®ä¾‹IDï¼Œä»¥åŠå±äºè¯¥äººç‰©èº«ä½“çš„å›¾ç‰‡åƒç´ å’Œä¸€ä¸ªæ¨¡æ¿3Dæ¨¡å‹ä¹‹é—´çš„æ˜ å°„ã€‚è¿™äº›æ³¨é‡Šåªå¯¹è®­ç»ƒå’ŒéªŒè¯å›¾åƒå…¬å¼€ã€‚

### CIFAR-10

 CIFAR-10æ•°æ®é›†ï¼ˆåŠ æ‹¿å¤§é«˜çº§ç ”ç©¶æ‰€ï¼Œ10ç±»ï¼‰æ˜¯Tiny Imagesæ•°æ®é›†çš„ä¸€ä¸ªå­é›†ï¼Œç”±60000å¼ 32x32çš„å½©è‰²å›¾åƒç»„æˆã€‚è¿™äº›å›¾åƒè¢«æ ‡è®°ä¸º10ä¸ªç›¸äº’æ’æ–¥çš„ç±»åˆ«ä¹‹ä¸€ï¼šé£æœºã€æ±½è½¦ï¼ˆä½†ä¸æ˜¯å¡è½¦æˆ–çš®å¡ï¼‰ã€é¸Ÿã€çŒ«ã€é¹¿ã€ç‹—ã€é’è›™ã€é©¬ã€èˆ¹å’Œå¡è½¦ï¼ˆä½†ä¸æ˜¯çš®å¡ï¼‰ã€‚æ¯ç±»æœ‰6000å¼ å›¾åƒï¼Œæ¯ç±»æœ‰5000å¼ è®­ç»ƒå›¾åƒå’Œ1000å¼ æµ‹è¯•å›¾åƒã€‚

 å†³å®šä¸€ä¸ªå›¾åƒæ˜¯å¦å±äºä¸€ä¸ªç±»åˆ«çš„æ ‡å‡†å¦‚ä¸‹ã€‚

- ç±»çš„åç§°åº”è¯¥åœ¨ "è¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"è¿™ä¸ªé—®é¢˜çš„å¯èƒ½ç­”æ¡ˆåˆ—è¡¨ä¸­ååˆ—å‰èŒ…ã€‚
- å›¾ç‰‡åº”è¯¥æ˜¯ç…§ç‰‡èˆ¬çœŸå®çš„ã€‚è´´æ ‡ç­¾è€…è¢«è¦æ±‚æ‹’ç»çº¿æç”»ã€‚
- å›¾ç‰‡åº”è¯¥åªåŒ…å«è¯¥ç±»åˆ«æ‰€æŒ‡çš„ç‰©ä½“çš„ä¸€ä¸ªçªå‡ºå®ä¾‹ã€‚è¯¥ç‰©ä½“å¯ä»¥æ˜¯éƒ¨åˆ†é®æŒ¡çš„ï¼Œæˆ–è€…æ˜¯ä»ä¸€ä¸ªä¸å¯»å¸¸çš„è§’åº¦çœ‹åˆ°çš„ï¼Œåªè¦è´´æ ‡è€…ä»ç„¶æ¸…æ¥šå…¶èº«ä»½ã€‚


### PASCAL-VOC

PASCAL VOCæ•°æ®é›†æ˜¯ç›®æ ‡æ£€æµ‹é¢†åŸŸæ¯”è¾ƒçŸ¥åçš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åˆ†ä¸ºVOC2007å’ŒVOC2012ä¸¤ä¸ªå­é›†ï¼Œå…¶å®˜æ–¹ä¸‹è½½åœ°å€å¦‚ä¸‹ï¼š
* [VOC2007-trainval](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar)
* [VOC2007-test](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar)
* [VOC2012-trainval](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar)
å®˜ç½‘æ—¶å¸¸ä¸ç¨³å®šï¼Œè¿›è€Œå¯¼è‡´ä¸‹è½½è¾ƒæ…¢ç”šè‡³ä¸‹è½½å¤±è´¥ï¼Œæ¨èä¸€å®šç¨³å®šçš„é•œåƒæºåœ°å€ï¼š[YOLOv3ä½œè€…ä¸»é¡µ](https://pjreddie.com/projects/pascal-voc-dataset-mirror/)


## èµåŠ©å’Œæ”¯æŒ

å¦‚æœä½ è§‰å¾—å®ƒå¯¹ä½ å¾ˆæœ‰å¸®åŠ©, è¯·ä½ ä¹Ÿåˆ†äº«ç»™éœ€è¦å­¦ä¹ çš„æœ‹å‹ä»¬ã€‚

å¦‚æœä½ çœ‹å¥½æˆ‘çš„ç»éªŒåˆ†äº«, ä¹Ÿè¯·è€ƒè™‘é€‚å½“çš„èµåŠ©æ‰“èµ, è®©æˆ‘èƒ½ç»§ç»­åˆ†äº«æ›´å¥½çš„å†…å®¹ç»™å¤§å®¶ã€‚



<table width="100%" border="0" cellspacing="15" cellpadding="0">
<tbody>
    <tr>
          <th>æ”¯ä»˜å®</th>
          <th>å¾®ä¿¡</th>
      </tr>
  <tr>
    <td>
      <img src="https://github.com/wuliwuxin/CV-Paper/blob/main/picture/AliPay.jpg"/>
    </td>
    <td width="50%">
        <p align="left"> 
        <p align="left"> <img src="https://github.com/wuliwuxin/CV-Paper/blob/main/picture/wechatPay.jpg" /> </p>
    </td>
   </tr>
</tbody>
</table>
