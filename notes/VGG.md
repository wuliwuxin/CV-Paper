---
title: VGG
date: 2021-07-06 12:48:06
author: wulixin
tags: 论文
summary: 文章主要讨论深度。为此，我们固定了架构的其他参数，并通过添加更多的卷积层来稳步增加网络的深度。
categories: 计算机视觉
---
#  带你读论文系列之计算机视觉--VGG

#  1 卷积和池化
## 卷积

**卷积只改变图片的深度**（深度与卷积核个数相同），不改变图片的深度和高度（padding方式为SAME，即补零）

**卷积核的作用：**
input image --> convolution kernel --> Feature map
图像处理时。给定输入图像，输入突袭那个中一个小区域中像素加权平均后成为输出图像中的

每一个对应像素。即最后feature map中的一个像素值
经过卷积核后图片大小计算公式：
**out_size=（in_size-F_size+2P）/S+1**
其中：F_size为卷积核大小；P为padding的大小；S为stride步长

## 池化

**池化只改变图片的深度核高度**，不改变图片深度

**池化作用：**
图片中的相邻像素倾向具有相似的值，因此通常卷积层相邻的输出像素也具有相似的值，这意味着卷积层输出中包含的大部分信息都是冗余的。

池化：通过减小输入的大小来降低输出的数量

**常见的池化方式：max pooling 和mean pooling**

传统视觉中，为了保证提取特征具有平移不变性，通常在提取特征前会进行高斯模糊的操作，所以CNN前期的网络中通常会采用mean pooling，后max pooling具有更好的效果（通常我们认为极值才是我们关注的特征，且max pooling增加了非线性，提高的网络的表达能力），且速度更快，所以**后期都采用max pooling，但是会导致CNN网络提取的特征不具有平移不变性，解决方案，增加blur操作**

> 论文参考https://arxiv.org/abs/1904.11486

#  2  论文背景
早在1989年，**Yann LeCun** (现纽约大学教授)和他的同事们就发表了卷积神经网络（Convolution NeuralNetworks， 简称CNN）的工作。在很长时间里，CNN虽然在小规模的问题上，如手写数字，取得过当时世界最好结果，但一直没有取得巨大成功。

2012年，**Alex和Hinton**参加ILSVRC2012比赛并提出AlexNet,首次在CNN中成功应用了ReLU、Dropout和LRN等Trick。同时AlexNet也使用了GPU进行运算加速。AlexNet将LeNet的思想发扬光大，把CNN的基本原理应用到了很深很宽的网络中。AlexNet为ILSVRC2012比赛的冠军，且远超第二名。

2014年，VGG网络被提出，其在AlexNet的基础上，运用了更小的卷积核，并且加深了网络，达到了更好的效果。

VGG于2014年由牛津大学科学工程系Visual Geometry Group组提出的。主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。VGG有两种结构，分别是VGG16和VGG19，两者除了网络深度不一样，其本质并没有什么区别。相对于2012年的AlexNet， VGG的一个高进是采用连续的3x3小卷积核来代替AlexNet中较大的卷积核（AlexNet采用了11x11，7x7与5x5大小的卷积核）。两个3x3步长为1的卷积核的叠加，其感受野相当与一个5x5的卷积核。但是采用堆积的小卷积核是由于大卷积核的，因为层数的增加，增加了网络的非线性，从而能让网络来学习更复杂的模型，并且小卷积核的参数更少。

VGG网络：是一个Deep CNN，具备CNN所有的功能，常用来提取特征图像。该网络使用3*3卷积对深度增加的网络进行研究，将深度推到6-19层。

在Localization和Classification  tasks都取得了很大的成就，并且在其他数据集上有很好的通用性。

**文章主要讨论深度。为此，我们固定了架构的其他参数，并通过添加更多的卷积层来稳步增加网络的深度。**

ConvNet架构设计的深度进行研究，**控制单一变量**（深度），固定了其他参数，并通过添加更多的卷积层来稳步增加网络的深度，因为在所有层中使用了非常小的（3×3）卷积滤波器。

之前Ciresan等人曾使用过小尺寸卷积滤波器。但他们的网络比我们的网络深度要小得多，而且他们没有对大规模的ILSVRC数据集进行评估。Goodfellow等人。将深度ConvNets（11个权重层）应用于街道号码识别任务，并**表明增加的深度导致更好的性能**。除了3×3，它们还使用1×1 和5×5卷积。然而，他们的网络拓扑比VGG网络的更复杂，并且特征图的空间分辨率在第一层中更积极地降低以减少计算量。1×1卷积本质上是在相同维度空间上的线性投影（1*1增加非线性，输入和输出通道的数量相同）。

#  论文
## VGG网络亮点

**与AlexNet相比亮点：**

1. 通过堆叠两个3*3的卷积核来的代替一个5*5的卷积核
2. 通过堆叠三个3*3的卷积核来代替一个7*7的卷积核

**好处**：可以减少参数量

假设输入特征矩阵和输出特征矩阵的深度（channel）为C

使用一个7*7卷积核所需参数：
7*7*C*C=49*C*C

使用三个3*3卷积核所需参数：
3*3*C*C+3*3*C*C+3*3*C*C=27*C*C

3个3*3比1个7*7节省(49-27)/27=81%参数。

## 感受野的计算

**感受野（receptive fields）**：输出feature map上的一个单元对应的输入层的区域大小。

计算公式：F(i) =  [F(i+1)-1]*stride+ksize

其中：F(i)为第i层的感受野；stride为 第i的步距；ksize为卷积核的大小。

例如：最后一层输出为一个单元：F = 1

conv3：F = (1-1)*1 + 3 =3

conv3：F = (3-1)*1 +3 =5

此时为两个3*3的卷积核代替一个5*5的卷积核。

conv3：F = (5-1)*1 +3 =7

此时为三个3*3的卷积核代替一个7*7的卷积核。

![网络结构](https://img-blog.csdnimg.cn/20210706123502806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

## 体系结构

1. 固定大小224*224RGB输入；
2. 唯一预处理是从每个像素中减去在训练集上计算的平均RGB值；
3. 用具有非常小的感受野的过滤器：3×3（这是捕捉左/右、上/下、中心概念的最小尺寸）；
4. 使用了1×1卷积滤波器，可以将其视为输入通道的线性变换（后跟非线性）；
5. 卷积步长固定为1像素；conv的空间填充，即卷积后保留空间分辨率，即填充为1像素，3×3卷积；
6. 空间池化是由五个最大池化层，最大池化在一个2×2像素的窗口上执行，步幅为2；
7. 后面是三个全连接层（FC层4096-4096-1000）：前两个层每个有4096个通道，第三个执行1000路ILSVRC分类，因此包含1000 个通道（每个通道一个）班级）。最后一层是soft-max层。全连接层的配置在所有网络中都是相同的。

所有隐藏层都配置了ReLU非线性函数。**该网络没有用局部相应归一化（LRN）**，因为这种规范化不**会提高ILSVRC数据集的性能，但会导致内存消耗和计算时间增加。**

![](https://img-blog.csdnimg.cn/20210706123615955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

卷积层参数表示为“*conv(感受野大小)-(通道数)*”。为简洁，未显示ReLU激活函数.

例如：conv3-64表示64个大小3*3的卷积核

conv3：卷积核大小3*3；stride=1；padding=1

maxpool：池化尺寸2*2；stride=2

只在深度上有所不同：从网络A的11个权重层（8个conv.和3个FC层）到网络E的19个权重层（16个conv.和3个FC层）。

网络D：conv3+FC=2+2+3+3+3+3=16

**maxpool和softmax不计入层数**

max pool和全连接层之间有一个flatten函数，把多维像素展平成一维像素，便于全连接层进行处理。

前两个全连接层：ReLU和Dropout

该网络可以看层两部分：最后一次全连接层（不包括）之前看为提取特征网络结构，三个全连接和softmax可看为分类结构。

## 网络的训练

ConvNet的训练过程一般遵循Krizhevsky等人（2012）的方法（除了从多尺度训练图像中对输入作物进行抽样）。训练是通过使用**min-batch梯度下降法**（基于反向传播）优化多叉逻辑回归目标来进行的，并带有动量。**batch size为256，momentum为0.9**。训练通过权重衰减（L2惩罚乘数设置为5·10e-4）和前两个全连接层的dropout正则化（**dropout比率为0.5**）进行正则化，Learning rate为0.01。然后在验证集准确性不再提高时，**学习率下降了3次，37万次迭代（74次）后停止。**

我们推测，尽管与Alex Net网络相比，我们的网络有更多的参数和更大的深度，但**网络需要更多的收敛时间**，这是因为（a）更大的深度和更小的conv.filter尺寸带来的隐性正则化；（b）某些层的预先初始化。

网络权重的初始化很重要，因为不好的初始化会因为深层网络中梯度的不稳定性而使学习停滞。

**网络A**足够浅，可以用**随机初始化**进行训练。然后，在训练更深的架构时，我们用网络A的层初始化前四个卷积层和最后三个全连接层（中间层随机初始化）。

## 图像处理

为了获得固定尺寸的**224×224ConvNet 输入图像**，它们被随机地从重新缩放的训练图像中裁剪出来（每个SGD迭代的图像裁剪一次）。为了进一步增加训练集，**将图像随机水平翻转和随机RGB颜色移动。**

S为resize后最小边，并且裁剪大小224*224。

虽然裁剪尺寸固定为224×224，但原则上S可以取不低于224的任何值：对于S=224，裁剪将捕获整个图像的统计数据，完全覆盖训练图像的最小一面；对于S远大于224，裁剪将对应于图像的一小部分，包含一个小物体或一个物体部分。

**两种方法来设置训练尺度S。**

**第一种是固定S**，对应于单尺度训练。两个固定尺寸：S=256和S=384；首先用S =256来训练网络。为了加快S=384 网络的训练，我们用S=256的权重进行初始化，并使用较小的初始学习率10的-3次方。

**第二种设置S**多尺度训练的方法其中每个训练图像通过从一定**范围[256，512]中随机采样**S来单独重新缩放。因为图像中的对象可能具有不同的大小。

## 测试

**1. 等比例缩放至Q，Q可以≠S
2. 稠密测试法：FC变卷积
3. 类分数图平均池化
4. 水平镜像**

在测试时，给定一个训练好的ConvNet和一个输入图像，按以下方式分类。首先，被重新**缩放到一个预先定义的最小图像边**，用Q表示（我们也把它称为测试尺度）。我们注意到**Q不一定等于训练规模S**。然后，网络以密集地应用于重新缩放的测试图像。即全连接层首先转换为卷积层（第一个FC层转换为7×7卷积层，最后两个FC层转换为1×1卷积层）。然后将所得的全卷积网络应用于整个（未裁剪的）图像。结果是一个类分数图，其通道数等于类数，空间分辨率可变，取决于输入图像的大小。最后，为了获得图像的类分数的固定大小向量，**对类分数图进行平均池化**。还通过图像的水平翻转来扩充测试集。对**原始图像和翻转图像**的soft-max类后验求平均以获得图像的最终分数。

![](https://img-blog.csdnimg.cn/20210706124016329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

首先，我们注意到使用局部响应归一化（A-LRN网络）并没有改进没有任何归一化层的模型A 。因此，我们不在更深层次的架构（B-E）中使用归一化。

其次，我们观察到**分类误差随着ConvNet深度的增加而降低**：从A中的11层到E中的19层。

值得注意的是，尽管深度相同，配置C（包含三个1×1卷积层）的性能比配置D在整个网络中使用3×3conv layers差**（D优于C）**。上图也表明**非线性确实有帮助（C比B 好）**，但使用conv捕获空间上下文也很重要。**当深度达到19层时，我们架构的错误率会饱和，但更深的模型可能对更大的数据集有益。证实了具有小过滤器的深网优于具有较大过滤器的浅网。**

![](https://img-blog.csdnimg.cn/20210706124109863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

测试时的尺度抖动导致更好的性能。最深的配置（D和E）表现最好，并且尺度抖动比固定最小边S的训练更好。在验证集上的最佳单网络性能是24.8%/7.5%top-1/top-5错误（在上表中以粗体突出显示）。在测试集上，配置E 实现了7.3%的top-5错误。

![](https://img-blog.csdnimg.cn/20210706124128761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdnimg.cn/20210706124132575.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

上表可以看出，使用**multi-crop比dense评估略好**，但它们的组合优于单一方式（multi-crop与dense互为补充）。multi-crop：150张（5*5*2*3=150）。

![](https://img-blog.csdnimg.cn/20210706124159826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)

表明深的ConvNets显着优于前一代模型。

## 发展分析

**瓶颈**

VGG耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。并且单纯的增加神经网络的深度，会给训练带来困难，会出现梯度消失、不收敛等问题。

**未来发展方向**

VGG的提出让研究员们看到网络的深度对结果的影响，并启发了他们去研究更深的网络。并且VGG网络的中间层能有效提取出输入图的feature，所以训练好的VGG模型通常会被运用到损失函数中间去，来弥补L2损失函数所造成的过于光滑的缺点。

![](https://img-blog.csdnimg.cn/20210706124315337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70)
